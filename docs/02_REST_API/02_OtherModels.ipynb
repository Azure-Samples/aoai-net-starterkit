{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 REST API | 02 Other Models (Whisper, Embedding, DALL-E)\n",
    "\n",
    "## Whisper - Speech to Text\n",
    "\n",
    "The Whisper model is a speech to text model from OpenAI that you can use to transcribe audio files. The model is trained on a large dataset of English audio and text. The model is optimized for transcribing audio files that contain speech in English. The model can also be used to transcribe audio files that contain speech in other languages. The output of the model is English text.\n",
    "\n",
    "- See the [documentation](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/whisper-overview) for more information about the Whisper model.\n",
    "- Get started with the Whisper model in this [Quickstart](https://learn.microsoft.com/en-us/azure/ai-services/openai/whisper-quickstart?tabs=command-line).\n",
    "\n",
    "\n",
    "## Embedding - Text to Vector\n",
    "\n",
    "Embeddings provide a vectorized representation of words or phrases, encapsulating their ***meaning*** and ***context***. Each embedding consists of a vector filled with floating-point numbers, where the distance between any two embeddings in this vector space signifies the semantic similarity between the respective inputs. In machine learning terminology, an embedding is recognized as a feature vector. Other examples of feature vectors include one-hot encoding and bag-of-words representations.\n",
    "\n",
    "- See the [documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=console) for more information about the Embedding model.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "In order to run this sample, you need to have the following pre-requisites:\n",
    "\n",
    "- Deploy the Whisper model to your OpenAI resource. See the [documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/whisper-quickstart?tabs=command-line#prerequisites) for more information.\n",
    "- Deploy the Embedding model to your OpenAI resource. See the [documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=console#prerequisites) for more information.\n",
    "\n",
    "## Samples\n",
    "\n",
    "The following samples demonstrate how to use the Whisper model to transcribe audio files and how to use the Embedding model to get the vector representation of words or phrases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: DotNetEnv, 2.5.0\"\n",
    "#r \"nuget: System.Text.Json, 7.0.3\"\n",
    "#r \"nuget: Newtonsoft.Json, 13.0.1\"\n",
    "using DotNetEnv;\n",
    "\n",
    "using System.Net;\n",
    "using System.Net.Http;\n",
    "using System.Net.Http.Headers;\n",
    "using System.Text.Json.Nodes;\n",
    "using System.Text.Json;\n",
    "using System.Collections.Generic;\n",
    "using System.Text.RegularExpressions;\n",
    "using System.IO;\n",
    "\n",
    "static string _configurationFile = @\"../01_DemoEnvironment/conf/application.env\";\n",
    "Env.Load(_configurationFile);\n",
    "\n",
    "string apiBase = Environment.GetEnvironmentVariable(\"SKIT_AOAI_ENDPOINT\"); \n",
    "string apiKey = Environment.GetEnvironmentVariable(\"SKIT_AOAI_APIKEY\"); \n",
    "string whisperDeploymentName = Environment.GetEnvironmentVariable(\"SKIT_WHISPER_DEPLOYMENTNAME\"); \n",
    "string adaDeploymentName = Environment.GetEnvironmentVariable(\"SKIT_EMBEDDING_DEPLOYMENTNAME\"); \n",
    "\n",
    "string apiVersion = \"2023-09-01-preview\";\n",
    "static int maxResponseToken = 200; \n",
    "int overallMaxTokens = 4096; \n",
    "string assetsFolder = Path.Combine(Directory.GetCurrentDirectory(), \"..\", \"..\", \"assets\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output\n",
    "```\n",
    "Installed Packages\n",
    "    DotNetEnv, 2.5.0\n",
    "    Newtonsoft.Json, 13.0.1\n",
    "    System.Text.Json, 7.0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Simple helper method to print a string to the console, wrapping lines at a given length\n",
    "static void PrintToConsole(string input, int maxLineLength)\n",
    "{\n",
    "    int currentIndex = 0;\n",
    "    while (currentIndex < input.Length)\n",
    "    {\n",
    "        // Determine the length of the substring to print\n",
    "        int length = Math.Min(maxLineLength, input.Length - currentIndex);\n",
    "        \n",
    "        // Find the last whitespace character in the substring\n",
    "        for (int i = currentIndex + length - 1; i >= currentIndex; i--)\n",
    "        {\n",
    "            if (char.IsWhiteSpace(input[i]))\n",
    "            {\n",
    "                length = i - currentIndex + 1;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Print the substring to the console\n",
    "        Console.WriteLine(input.Substring(currentIndex, length));\n",
    "        \n",
    "        // Update the current index\n",
    "        currentIndex += length;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Transcribe audio file with the Whisper model\n",
    "\n",
    "For this sample, we have included a `wikipediaOcelot.wav` file to be used as an example. You can use your own audio file by changing the `filePath` variable.\n",
    "\n",
    "Additional sample audio files can be found in the [Cognitive Services Speech sample data](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "string filePath = Path.Combine(assetsFolder, \"docs\" , \"02_REST_API\", \"wikipediaOcelot.wav\");\n",
    "string endpoint = $\"{apiBase}openai/deployments/{whisperDeploymentName}/audio/transcriptions?api-version={apiVersion}\";\n",
    "\n",
    "using (HttpClient httpClient = new HttpClient())\n",
    "using (var formData = new MultipartFormDataContent())\n",
    "using (var fileContent = new StreamContent(File.OpenRead(filePath)))\n",
    "{\n",
    "    httpClient.BaseAddress = new Uri(endpoint);\n",
    "    httpClient.DefaultRequestHeaders.Add(\"api-key\",apiKey);\n",
    "\n",
    "    formData.Add(fileContent, \"file\", Path.GetFileName(filePath));\n",
    "    fileContent.Headers.ContentType = new MediaTypeHeaderValue(\"multipart/form-data\");\n",
    "    var response = await httpClient.PostAsync(endpoint, formData);\n",
    "\n",
    "    if (response.IsSuccessStatusCode)\n",
    "    {\n",
    "        var responseBody = await response.Content.ReadAsStringAsync();\n",
    "        PrintToConsole(responseBody,80);\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine($\"Error: {response}\");        \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output\n",
    "```\n",
    "{\"text\":\"The ocelot, Lepardus paradalis, is a small wild cat native to the \n",
    "southwestern United States, Mexico, and Central and South America. This \n",
    "medium-sized cat is characterized by solid black spots and streaks on its coat, \n",
    "round ears, and white neck and undersides. It weighs between 8 and 15.5 \n",
    "kilograms, 18 and 34 pounds, and reaches 40 to 50 centimeters – 16 to 20 inches \n",
    "– at the shoulders. It was first described by Carl Linnaeus in 1758. Two \n",
    "subspecies are recognized, L. p. paradalis and L. p. mitis. Typically active \n",
    "during twilight and at night, the ocelot tends to be solitary and territorial. \n",
    "It is efficient at climbing, leaping, and swimming. It preys on small \n",
    "terrestrial mammals such as armadillo, opossum, and \n",
    "lagomorphs.\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Get Embedding for a word or phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string query = \"What is the capital of Germany?\";\n",
    "endpoint = $\"{apiBase}openai/deployments/{adaDeploymentName}/embeddings?api-version={apiVersion}\";\n",
    "\n",
    "using (HttpClient httpClient = new HttpClient())\n",
    "{\n",
    "    httpClient.BaseAddress = new Uri(endpoint);\n",
    "    httpClient.DefaultRequestHeaders.Add(\"api-key\",apiKey);\n",
    "    \n",
    "    // Create HttpContent and set its ContentType\n",
    "    string jsonQuery = $\"{{\\\"input\\\":\\\"{query}\\\"}}\";\n",
    "    HttpContent content = new StringContent(jsonQuery, Encoding.UTF8, \"application/json\");\n",
    "    HttpResponseMessage response = await httpClient.PostAsync(\"\", content);\n",
    "        if (response.IsSuccessStatusCode)\n",
    "        {\n",
    "            string result = await response.Content.ReadAsStringAsync();\n",
    "            Console.WriteLine(result);\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            Console.WriteLine($\"Error: {response.ReasonPhrase}\");\n",
    "        }\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "See how you can use JSON mode to get JSON formatted results from a LLM call. [JSON Mode](./03_JsonMode.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
