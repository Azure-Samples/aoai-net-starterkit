{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 SDK | 01 Chat Completion\n",
    "\n",
    "## Azure Environment\n",
    "\n",
    "You can create the necessary instance of Azure OpenAI and deploy an embedding model by executing one of the deployment options [mentioned here](../../create_env/src/AzureCLI/CreateEnv.azcli). To execute the sample code service specific information is needed ([Details and instructions here](../01_DemoEnvironment/01_Environment.ipynb)) \n",
    "\n",
    "## Step 1: Create OpenAIClient\n",
    "\n",
    "The OpenAIClient from Azure.AI.OpenAI is a .NET client library that acts as the centralized point for all .NET functionality that want to interact with a deployed Azure OpenAI Large Language Model. It provides methods to access the OpenAI REST APIs for various tasks such as text completion, text embedding, and chat completion, etc.. It also allows developers to specify the model, engine, and options for each request, such as temperature, frequency penalty, presence penalty, and stop sequences. \n",
    "\n",
    "The OpenAIClient can connect to any Azure OpenAI resource or to the non-Azure OpenAI inference endpoint, making it a versatile and powerful tool for .NET development with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.8\"\n",
    "#r \"nuget: DotNetEnv, 2.5.0\"\n",
    "\n",
    "using Azure; \n",
    "using Azure.AI.OpenAI;\n",
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "using System.Text.Json; \n",
    "\n",
    "//configuration file is created during environment creation\n",
    "//if you skipped the deployment just remove the code and provide values from your deployment\n",
    "static string _configurationFile = @\"../01_DemoEnvironment/conf/application.env\";\n",
    "Env.Load(_configurationFile);\n",
    "\n",
    "\n",
    "string assetsFolder = Path.Combine(Directory.GetCurrentDirectory(), \"..\", \"..\", \"assets\");\n",
    "\n",
    "string oAiApiKey = Environment.GetEnvironmentVariable(\"SKIT_AOAI_APIKEY\") ?? \"SKIT_AOAI_APIKEY not found\";\n",
    "string oAiEndpoint = Environment.GetEnvironmentVariable(\"SKIT_AOAI_ENDPOINT\") ?? \"SKIT_AOAI_ENDPOINT not found\";\n",
    "string chatCompletionDeploymentName = Environment.GetEnvironmentVariable(\"SKIT_CHATCOMPLETION_DEPLOYMENTNAME\") ?? \"SKIT_CHATCOMPLETION_DEPLOYMENTNAME not found\";\n",
    "\n",
    "AzureKeyCredential azureKeyCredential = new AzureKeyCredential(oAiApiKey);\n",
    "OpenAIClient openAIClient = new OpenAIClient(new Uri(oAiEndpoint), azureKeyCredential);\n",
    "\n",
    "Console.WriteLine($\"OpenAI Client created...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "Installed Packages\n",
    "    Azure.AI.OpenAI, 1.0.0-beta.8\n",
    "    DotNetEnv, 2.5.0\n",
    "\n",
    "OpenAI Client created...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic interaction with OpenAI Client\n",
    "\n",
    "The following cell, demonstrate a basic interaction with OpenAI Client. In this case, the system message is used to provide instructions or settings for the assistant, such as its personality or behavior. The user message is used to provide queries or inputs from the human user. The assistant message is used to provide responses or outputs from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "string sys_prompt = \"You are an AI assistance. You extract intention from provided text. You always answer with intention:\";\n",
    "ChatCompletionsOptions simpleOption = new ChatCompletionsOptions();\n",
    "\n",
    "simpleOption.Messages.Add(new ChatMessage(ChatRole.System, sys_prompt));\n",
    "\n",
    "simpleOption.Messages.Add(new ChatMessage(ChatRole.User, \"I'm not receiving calls on my Samsung Galaxy S22. Can you help?\"));\n",
    "\n",
    "//Request Properties\n",
    "simpleOption.MaxTokens = 500;\n",
    "simpleOption.Temperature = 0.0f;\n",
    "simpleOption.NucleusSamplingFactor = 0.0f;\n",
    "simpleOption.FrequencyPenalty = 0.7f;\n",
    "simpleOption.PresencePenalty = 0.7f;\n",
    "simpleOption.StopSequences.Add(\"\\n\"); \n",
    "\n",
    "\n",
    "// Call the Model ChatCompletions endpoint\n",
    "Response<ChatCompletions> simpleResponse = await openAIClient.GetChatCompletionsAsync(\n",
    "    chatCompletionDeploymentName, \n",
    "    simpleOption);\n",
    "\n",
    "// Get the first choice from the response\n",
    "ChatCompletions simpleCompletions = simpleResponse.Value;\n",
    "foreach (ChatChoice chatChoice in simpleCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"Content: {chatChoice.Message.Content}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "ChatChoiceIndex: 0\n",
    "Content: Intention: Request for technical assistance with phone call issue on Samsung Galaxy S22.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compose Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//Define System Prompt\n",
    "string system = @\" \n",
    "        You extract intention from provided text. The two intentions you identify are: product information and order status. \n",
    "        You answer with a valid JSON string. \n",
    "        The JSON string must have the format {\"\"Intention\"\": \"\"ProductInformation\"\"} or {\"\"Intention\"\": \"\"OrderInfo\"\"}. \n",
    "        You don't provide additional information. \n",
    "        If you can't identify intention answer with {\"\"Intention\"\": \"\"Unknown\"\"}\n",
    "\";\n",
    "\n",
    "//Compose Chat (Few Shot Learning)\n",
    "ChatCompletionsOptions chatCompletionsOptions = new ChatCompletionsOptions();\n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.System, system));\n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.User, \"I've purchased three weeks ago new training shoes. When will they will be delivered?\"));\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.Assistant, \"{\\\"Intention\\\": \\\"OrderInfo\\\"}\")); \n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.User, \"Still waiting for the delivery. Any idea when it will arrive? I'm Robert and I'm calling on behalf of company Contoso.\"));\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.Assistant, \"{\\\"Intention\\\": \\\"OrderInfo\\\"}\")); \n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.User, \"Do you have training shoes? If yes, I'm interested in running equipment specifically running shoes.\"));\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.Assistant, \"{\\\"Intention\\\": \\\"ProductInfo\\\"}\")); \n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.User, \"What is the average price for running shoes?\"));\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.Assistant, \"{\\\"Intention\\\": \\\"ProductInfo\\\"}\")); \n",
    "\n",
    "//Request Properties\n",
    "chatCompletionsOptions.MaxTokens = 500;\n",
    "chatCompletionsOptions.Temperature = 0.0f;\n",
    "chatCompletionsOptions.NucleusSamplingFactor = 0.0f;\n",
    "chatCompletionsOptions.FrequencyPenalty = 0.7f;\n",
    "chatCompletionsOptions.PresencePenalty = 0.7f;\n",
    "chatCompletionsOptions.StopSequences.Add(\"\\n\"); \n",
    "\n",
    "//Choices per prompt\n",
    "chatCompletionsOptions.ChoiceCount = 2;\n",
    "\n",
    "Console.WriteLine(\"ChatCompletionsOptions created...\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "ChatCompletionsOptions created...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Call OpenAI ChatCompletion Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Add user input to the chat completions options\n",
    "chatCompletionsOptions.Messages.Add(new ChatMessage(ChatRole.User, \"How much do you charge for a pair of first class running shoes?\")); \n",
    "\n",
    "// Call the Model ChatCompletions endpoint\n",
    "Response<ChatCompletions> response = await openAIClient.GetChatCompletionsAsync(\n",
    "    chatCompletionDeploymentName, \n",
    "    chatCompletionsOptions);\n",
    "\n",
    "// Get the first choice from the response\n",
    "ChatCompletions chatCompletions = response.Value;\n",
    "foreach (ChatChoice chatChoice in chatCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"Content: {chatChoice.Message.Content}\");\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "ChatChoiceIndex: 0\n",
    "Content: {\"Intention\": \"ProductInfo\"}\n",
    "ChatChoiceIndex: 1\n",
    "Content: {\"Intention\": \"ProductInfo\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check additional response values\n",
    "\n",
    "### Token Usage\n",
    "\n",
    "Tokens consumed by the `GetChatCompletionsAsync()` call can be retrieved by parsing the raw response from the call as the `\"nuget: Azure.AI.OpenAI, 1.0.0-beta.7\"` does not provide the information as property yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//Get Raw Response\n",
    "var rawResponse = response.GetRawResponse();\n",
    "if (!rawResponse.IsError) {\n",
    "    //Get Raw Response Content\n",
    "    JsonElement jsonElement = JsonSerializer.Deserialize<JsonElement>(rawResponse.Content.ToString());\n",
    "    JsonElement tokenUsage = jsonElement.GetProperty(\"usage\");\n",
    "    tokenUsage.TryGetProperty(\"completion_tokens\", out JsonElement completionTokens);\n",
    "    Console.WriteLine($\"Completion Tokens: {completionTokens.ToString()}\");\n",
    "    tokenUsage.TryGetProperty(\"prompt_tokens\", out JsonElement promptTokens);\n",
    "    Console.WriteLine($\"Prompt Tokens: {promptTokens.ToString()}\");\n",
    "    tokenUsage.TryGetProperty(\"total_tokens\", out JsonElement totalTokens);\n",
    "    Console.WriteLine($\"Total Tokens: {totalTokens.ToString()}\");\n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "Completion Tokens: <value>\n",
    "Prompt Tokens: <value>\n",
    "Total Tokens: <value>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter \n",
    "\n",
    "If the LLM detects:\n",
    "- hate\n",
    "- self harm\n",
    "- violence\n",
    "- sexual\n",
    "content within the provided prompt or in the result it will be filtered and reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//Prompt Filter\n",
    "Console.WriteLine($\"Prompt Filter Results\");\n",
    "foreach(PromptFilterResult promptFilterResult in chatCompletions.PromptFilterResults) {\n",
    "    Console.WriteLine($\"PromptIndex: {promptFilterResult.PromptIndex}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Hate\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.Hate.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.Hate.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: SelfHarm\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.SelfHarm.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.SelfHarm.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Violence\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.Violence.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.Violence.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Sexual\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.Sexual.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.Sexual.Severity}\");\n",
    "}\n",
    "\n",
    "//Response Filter\n",
    "foreach (ChatChoice chatChoice in chatCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Hate\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.Hate.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.Hate.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: SelfHarm\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.SelfHarm.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.SelfHarm.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Violence\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.Violence.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.Violence.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Sexual\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.Sexual.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.Sexual.Severity}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output\n",
    "\n",
    "```\n",
    "Prompt Filter Results\n",
    "ChatChoiceIndex: 0\n",
    "\t ContentFilterResults: Hate\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: SelfHarm\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Violence\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Sexual\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "ChatChoiceIndex: 1\n",
    "\t ContentFilterResults: Hate\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: SelfHarm\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Violence\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Sexual\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- The result from the result was received as a single object. Streaming is useful in scenario where the response is large, and the client wants to process the response as it is received. [Demo Streaming](./02_ChatCompletionStreaming.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
