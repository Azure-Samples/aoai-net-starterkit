{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 SDK | 04 Multi Modal Vision\n",
    "\n",
    "## TODO\n",
    "\n",
    "\n",
    "\n",
    "### Further information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Environment\n",
    "\n",
    "To execute the sample code Azure service specific information like endpoint, api key etc. is needed ([Details and instructions can be found here](../01_DemoEnvironment/01_Environment.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create OpenAIClient\n",
    "\n",
    "The OpenAIClient from Azure.AI.OpenAI is a .NET client library that acts as the centralized point for all .NET functionality that want to interact with a deployed Azure OpenAI Large Language Model. It provides methods to access the OpenAI REST APIs for various tasks such as text completion, text embedding, and chat completion, etc.. It also allows developers to specify the model, engine, and options for each request, such as temperature, frequency penalty, presence penalty, and stop sequences. \n",
    "\n",
    "The OpenAIClient can connect to any Azure OpenAI resource or to the non-Azure OpenAI inference endpoint, making it a versatile and powerful tool for .NET development with OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.12\"\n",
    "#r \"nuget: DotNetEnv, 2.5.0\"\n",
    "\n",
    "using Azure; \n",
    "using Azure.AI.OpenAI;\n",
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "using System.Text.Json; \n",
    "\n",
    "//configuration file is created during environment creation\n",
    "//if you skipped the deployment just remove the code and provide values from your deployment\n",
    "static string _configurationFile = @\"../01_DemoEnvironment/conf/application.env\";\n",
    "Env.Load(_configurationFile);\n",
    "\n",
    "string oAiApiKey = Environment.GetEnvironmentVariable(\"SKIT_AOAI4Vision_APIKEY\") ?? \"SKIT_AOAI1106_APIKEY not found\";\n",
    "string oAiEndpoint = Environment.GetEnvironmentVariable(\"SKIT_AOAI4Vision_ENDPOINT\") ?? \"SKIT_AOAI1106_ENDPOINT not found\";\n",
    "string chatCompletionDeploymentName = Environment.GetEnvironmentVariable(\"SKIT_AOAI4Vision_DEPLOYMENTNAME\") ?? \"SKIT_AOAI1106_DEPLOYMENTNAME not found\";\n",
    "string storageConnectionString = Environment.GetEnvironmentVariable(\"SKIT_STORAGE_CONNECTIONSTRING\") ?? \"SKIT_STORAGE_CONNECTIONSTRING not found\";\n",
    "string assetsFolder = Path.Combine(Directory.GetCurrentDirectory(), \"..\", \"..\", \"assets\");\n",
    "\n",
    "AzureKeyCredential azureKeyCredential = new AzureKeyCredential(oAiApiKey);\n",
    "OpenAIClient openAIClient = new OpenAIClient(new Uri(oAiEndpoint), azureKeyCredential);\n",
    "\n",
    "\n",
    "Console.WriteLine($\"OpenAI Client created...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "Installed Packages\n",
    "    Azure.AI.OpenAI, 1.0.0-beta.12\n",
    "    DotNetEnv, 2.5.0\n",
    "\n",
    "OpenAI Client created...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload image to Azure Storage and crate Shared Access Signature\n",
    "\n",
    "We expect the LLM to identify the attraction provided in this image: ![LittleMermaid](../../assets/docs/03_SDK/LittleMermaid.jpg) \n",
    "\n",
    "It should deliver the name, location and country of the attraction. The LLM expects a Url to the image which should be analyzed therefore we upload the image to a Storage Account and crate a Shared Access Signature which will be provided to the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.Storage.Blobs\"\n",
    "\n",
    "using Azure.Storage.Blobs;\n",
    "using Azure.Storage.Sas;\n",
    "\n",
    "string containerName = \"skit\";\n",
    "string blobName = \"LittleMermaid.jpg\";\n",
    "string localFilePath = \"../../assets/docs/03_SDK/LittleMermaid.jpg\";\n",
    "string sasUrl = \"\";\n",
    "\n",
    "BlobServiceClient blobServiceClient = new BlobServiceClient(storageConnectionString);\n",
    "BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName); \n",
    "containerClient.CreateIfNotExists();\n",
    "\n",
    "BlobClient blobClient = containerClient.GetBlobClient(blobName);\n",
    "using (FileStream fileStream = new FileStream(localFilePath, FileMode.Open)){\n",
    "    await blobClient.UploadAsync(fileStream, true);\n",
    "    BlobSasBuilder sasBuilder = new BlobSasBuilder() {\n",
    "        BlobContainerName = containerName,\n",
    "        BlobName = blobClient.Name,\n",
    "        Resource = \"b\"\n",
    "    };\n",
    "    sasBuilder.ExpiresOn = DateTimeOffset.UtcNow.AddDays(1);\n",
    "    sasBuilder.SetPermissions(BlobContainerSasPermissions.Read);\n",
    "\n",
    "    sasUrl = blobClient.GenerateSasUri(sasBuilder).ToString();\n",
    "}\n",
    "Console.WriteLine($\"Blob uploaded to {sasUrl}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output: \n",
    "```\n",
    "Blob uploaded to <<Url with SaS>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compose ChatCompletionsOptions\n",
    "\n",
    "Each chat would follow similar structure, where _System_, _Agent_ and _User_ messages are added in sequence. Parameters, such as _Temperature_ could be set per call. We can provide the the image url and the user message containing instructions how to process the image using: \n",
    "\n",
    "```csharp\n",
    "new ChatRequestUserMessage(\n",
    "    new ChatMessageTextContentItem(userMessage),\n",
    "    new ChatMessageImageContentItem(new Uri(sasUrl))\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//Define System Prompt\n",
    "string systemMessage = @\" \n",
    "    You are an assistant who helps travel agency staff to find interesting attractions around the world. \n",
    "    You name the place of interest, the city and the country in which the attraction is located. \n",
    "    You do not provide any further information.\n",
    "\"; \n",
    "\n",
    "string userMessage = @\"\n",
    "    Which place of interest is this?\n",
    "\";\n",
    "\n",
    "//Compose Chat (Simplified - No few shot learning in this example)\n",
    "ChatCompletionsOptions chatCompletionsOptions = new ChatCompletionsOptions()\n",
    "{\n",
    "    DeploymentName = chatCompletionDeploymentName,\n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage(systemMessage),\n",
    "        new ChatRequestUserMessage(userMessage),\n",
    "        new ChatRequestUserMessage(\n",
    "            new ChatMessageTextContentItem(userMessage),\n",
    "            new ChatMessageImageContentItem(new Uri(sasUrl))\n",
    "        )\n",
    "    },\n",
    "    MaxTokens = 100, \n",
    "    NucleusSamplingFactor = 0.1f,\n",
    "    Temperature = 0.1f,\n",
    "};\n",
    "\n",
    "Console.WriteLine($\"ChatCompletionsOptions created...\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "ChatCompletionsOptions created...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Call ChatCompletion API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "Response<ChatCompletions> response = await openAIClient.GetChatCompletionsAsync(chatCompletionsOptions);\n",
    "Console.WriteLine(response.Value.Choices[0].Message.Content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "The Little Mermaid statue, Copenhagen, Denmark.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- The concept of Embeddings allows transforming information into a numerical representation preserving the semantic context of the information: [Demo Embeddings](../04_Embeddings/01_BasicEmbeddings.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
